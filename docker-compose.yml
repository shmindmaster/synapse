# ============================================
# Synapse Docker Compose (Cloud AI Mode)
# ============================================
# Use this for development with cloud AI providers (OpenAI, Azure, etc.)
# Database runs in Docker, AI uses cloud APIs
#
# Usage:
#   docker compose up -d
#
# Documentation: README.md
# ============================================

services:
  postgres:
    image: pgvector/pgvector:pg16
    container_name: synapse-postgres
    environment:
      POSTGRES_USER: synapse
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-synapse}
      POSTGRES_DB: synapse
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U synapse"]
      interval: 5s
      timeout: 5s
      retries: 5
    command: >
      postgres -c shared_preload_libraries=vector -c max_connections=200
    networks:
      - synapse-network

  backend:
    build:
      context: .
      dockerfile: src/api/Dockerfile
    container_name: synapse-backend
    environment:
      # Infrastructure
      - NODE_ENV=${NODE_ENV:-production}
      - PORT=8000
      - DATABASE_URL=postgresql://synapse:${POSTGRES_PASSWORD:-synapse}@postgres:5432/synapse
      
      # Authentication
      - AUTH_SECRET=${AUTH_SECRET:-change-this-in-production}
      
      # Cloud AI Provider
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MODEL_CHAT=${MODEL_CHAT:-gpt-4o}
      - MODEL_FAST=${MODEL_FAST:-gpt-3.5-turbo}
      - MODEL_EMBEDDING=${MODEL_EMBEDDING:-text-embedding-3-small}
      - EMBEDDING_DIMENSIONS=${EMBEDDING_DIMENSIONS:-1536}
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-100}
      
      # CORS
      - CORS_ORIGIN=${CORS_ORIGIN:-http://localhost:3000}
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    networks:
      - synapse-network

  frontend:
    build:
      context: .
      dockerfile: src/web/Dockerfile
      args:
        VITE_API_URL: ${VITE_API_URL:-http://localhost:8000}
    container_name: synapse-frontend
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - synapse-network

volumes:
  postgres_data:
    driver: local

networks:
  synapse-network:
    driver: bridge
