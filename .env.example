# ==========================================
# Synapse Configuration
# ==========================================
# Copy this file to .env and fill in your values

# ==========================================
# 1. APPLICATION SETTINGS
# ==========================================
NODE_ENV=development
APP_NAME=synapse
PORT=8000

# ==========================================
# 2. DATABASE
# ==========================================
# PostgreSQL connection string (required)
# Format: postgresql://user:password@host:port/database?sslmode=require
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/synapse"

# Optional: Separate connection for direct (non-pooled) access
DATABASE_URL_UNPOOLED="${DATABASE_URL}"

# PostgreSQL SSL mode (disable, allow, prefer, require, verify-ca, verify-full)
PGSSLMODE=prefer

# ==========================================
# 3. AUTHENTICATION
# ==========================================
# Secret key for JWT token generation (change in production!)
AUTH_SECRET="change-this-to-a-random-secret-in-production"

# ==========================================
# 4. AI & INFERENCE
# ==========================================
# Choose your AI provider and configure accordingly

# --- OpenAI ---
OPENAI_API_KEY=""
OPENAI_API_BASE="https://api.openai.com/v1"

# --- Anthropic ---
ANTHROPIC_API_KEY=""

# --- Google Gemini ---
GEMINI_API_KEY=""

# --- Groq (Fast LLaMA inference) ---
GROQ_API_KEY=""

# --- Cerebras (Fast inference) ---
CEREBRAS_API_KEY=""

# --- ElevenLabs (Text-to-Speech) ---
ELEVENLABS_API_KEY=""

# --- Model Selection ---
# Specify which models to use (provider-specific model names)
MODEL_CHAT="gpt-4o"                      # Primary reasoning model
MODEL_FAST="gpt-3.5-turbo"               # Fast operations model
MODEL_EMBEDDING="text-embedding-3-small" # Embeddings model
MODEL_IMAGE="dall-e-3"                   # Image generation (optional)
MODEL_TTS="tts-1"                        # Text-to-speech (optional)

# ==========================================
# 5. OBJECT STORAGE (Optional)
# ==========================================
# S3-compatible object storage for file uploads
# Leave blank to use local file system

# AWS S3 or compatible service (DigitalOcean Spaces, MinIO, etc.)
OBJECT_STORAGE_KEY=""
OBJECT_STORAGE_SECRET=""
OBJECT_STORAGE_ENDPOINT="https://s3.amazonaws.com"  # Or your S3-compatible endpoint
OBJECT_STORAGE_BUCKET="synapse-storage"
OBJECT_STORAGE_REGION="us-east-1"

# Optional: Prefix for this app's files (useful for shared buckets)
OBJECT_STORAGE_PREFIX="synapse/"

# ==========================================
# 6. FRONTEND CONFIGURATION
# ==========================================
# URLs for frontend to connect to backend
VITE_API_URL="http://localhost:8000"
VITE_APP_URL="http://localhost:3000"

# ==========================================
# 7. OBSERVABILITY (Optional)
# ==========================================
# Sentry for error tracking
SENTRY_DSN=""

# Enable debug logging
DEBUG=false

# ==========================================
# 8. VECTOR DATABASE (pgvector)
# ==========================================
# Optional: Separate connection for vector operations
# If not set, uses DATABASE_URL
VECTOR_DB_URL="${DATABASE_URL}"

# Vector embedding dimensions (depends on your embedding model)
VECTOR_DIMENSIONS=1536  # text-embedding-3-small uses 1536 dimensions

# ==========================================
# Notes:
# ==========================================
# - Replace all placeholder values with your actual credentials
# - Never commit this file with real credentials
# - Use different secrets for development and production
# - For production, use environment variables or a secrets manager
# - Keep your API keys secure and rotate them regularly
