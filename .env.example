# ======================================================
# 1. APP IDENTITY
# ======================================================
APP_SLUG=synapse
APP_ENV=prod
APP_PUBLIC_HOST=synapse.shtrial.com
APP_API_HOST=api.synapse.shtrial.com

# ======================================================
# 2. DATA LAYER (DIGITALOCEAN MANAGED POSTGRESQL)
# ======================================================
# Example connection string for the shared DigitalOcean cluster `sh-shared-postgres`
# with a per-repo database named "Synapse". Replace <DB_PASSWORD> and host suffixes
# with values from your organization-level `.env.shared`.
DATABASE_URL="postgresql://doadmin:<DB_PASSWORD>@sh-shared-postgres-do-user-XXXX.f.db.ondigitalocean.com:25060/Synapse?sslmode=require"

# ======================================================
# 3. STORAGE (DIGITALOCEAN SPACES)
# ======================================================
# Bucket: synapse (lowercase repo slug)
DO_SPACES_ENDPOINT=https://nyc3.digitaloceanspaces.com
DO_SPACES_BUCKET=synapse
DO_SPACES_KEY=<SPACES_ACCESS_KEY>
DO_SPACES_SECRET=<SPACES_SECRET_KEY>
DO_SPACES_REGION=nyc3
DO_SPACES_CDN_ENDPOINT=https://synapse.nyc3.cdn.digitaloceanspaces.com

# Public CDN URL (for frontend use)
NEXT_PUBLIC_CDN_BASE_URL=https://synapse.nyc3.cdn.digitaloceanspaces.com

# ======================================================
# 4. AI ENGINE (DIGITALOCEAN GRADIENT AI - OPENAI COMPATIBLE)
# ======================================================
# Serverless inference endpoint (OpenAI-compatible)
DIGITALOCEAN_INFERENCE_ENDPOINT=https://inference.do-ai.run/v1
AI_PROVIDER=digitalocean
AI_MODEL=llama-3.1-70b-instruct
AI_MODEL_EMBEDDING=text-embedding-3-small

# Model access key (keep secret in real environments)
DIGITALOCEAN_MODEL_KEY=<GRADIENT_MODEL_KEY>

# Optional: generic OpenAI-compatible fallback
OPENAI_API_KEY=<OPTIONAL_OPENAI_COMPATIBLE_KEY>
OPENAI_BASE_URL=https://api.openai.com/v1

